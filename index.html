
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Shaohao Rui</title>
    <style>
        body {
            font-family: "Segoe UI", sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f9f9f9;
            color: #333;
        }
        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 2rem;
        }
        header {
            display: flex;
            align-items: center;
            margin-bottom: 2rem;
        }
        header img {
            border-radius: 50%;
            width: 120px;
            height: 120px;
            margin-right: 1.5rem;
        }
        h1 {
            margin: 0;
            font-size: 2rem;
        }
        section {
            margin-bottom: 2rem;
        }
        h2 {
            border-bottom: 2px solid #eee;
            padding-bottom: 0.25rem;
        }
        .publication img {
            width: 200px;
            margin-top: 0.5rem;
        }
        .pub-text {
            margin-left: 220px;
            margin-top: -200px;
        }
        .contact-icons span {
            margin-right: 1rem;
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <img src="https://via.placeholder.com/120" alt="Profile Picture">
            <div>
                <h1>Shaohao Rui</h1>
                <p>Ph.D. student at Fudan University and Shanghai Innovation Institute, advised by Prof. Xiangyang Xue, Prof. Yanwei Fu, and Prof. Binxing Fang.</p>
                <p>üìç Shanghai, China | üìß <a href='mailto:ruishaohao@sjtu.edu.cn'>ruishaohao@sjtu.edu.cn</a> | üêô <a href='https://github.com/shaohao011'>GitHub</a> | üîé <a href='https://scholar.google.cz/citations?user=75EJxB4AAAAJ&hl=zh-CN&oi=ao'>Google Scholar</a></p>
            </div>
        </header>

        <section>
            <h2>üßë‚Äçüíª About me</h2>
            <p>I am passionate about developing AI systems that integrate perception, reasoning, and action in complex environments. My work primarily involves 3D multi-modal reconstruction and how it can enable robotic manipulation.</p>
        </section>

        <section>
            <h2>üî• News</h2>
            <ul>
                <li><strong>2025.04:</strong> Attending China3DV at Beijing, China.</li>
                <li><strong>2025.02:</strong> üéâ Our works on 3D Visual Grounding and Reasoning have been accepted by CVPR 2025.</li>
            </ul>
        </section>

        <section>
            <h2>üìÑ Publications</h2>
            <div class="publication">
                <img src="https://via.placeholder.com/200x150?text=CVPR+2025" alt="Paper image">
                <div class="pub-text">
                    <p><a href="#">ReasonGrounder: LVLM-Guided Hierarchical Feature Splatting for Open-Vocabulary 3D Visual Grounding and Reasoning</a><br>
                    Shaohao Rui, Yikai Wang, Sixiao Zheng, Tongying Pan, Longfei Liang, Yanwei Fu, Xiangyang Xue, <strong>CVPR 2025</strong></p>
                    <p>Project: A novel LVLM-guided framework that uses 3D feature Gaussian fields for adaptive grouping and open-vocabulary 3D grounding.</p>
                </div>
            </div>
        </section>

        <section>
            <h2>üíº Internships</h2>
            <ul>
                <li><strong>2025.04 - 2025.10</strong>, Shanghai AI Laboratory, Shanghai, China</li>
                <li><strong>2021.04 - 2024.06</strong>, Media Intelligence Laboratory, Hangzhou, China</li>
            </ul>
        </section>
    </div>
</body>
</html>
